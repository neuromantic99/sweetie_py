{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://photos1.blogger.com/blogger/6296/2252/1600/untitled3.jpg',\n",
       " 'http://i926.photobucket.com/albums/ad104/BigBlueCowboy/ThomasRoberts.jpg',\n",
       " 'http://www.me-me-me.tv/images/2011/10/Thomas-Jane.jpg',\n",
       " 'http://2.bp.blogspot.com/-_0r-vD8K3sM/T9mfvahapnI/AAAAAAAAINA/s7c4lFxiJGM/s1600/Tom+Cruise+gay.jpg',\n",
       " 'http://4.bp.blogspot.com/-Cx3GTeCBqe8/TwX8NtezJGI/AAAAAAAAB-0/Mvx3cB275_w/s1600/gareth-thomas-1.jpg',\n",
       " 'http://images.digitalspy.co.uk/08/16/w550_tom_welling.jpg',\n",
       " 'http://www.pinknews.co.uk/images/2009/12/gareththomasrugby.jpg',\n",
       " 'http://a.dilcdn.com/bl/wp-content/uploads/sites/8/2011/02/SGG-031755.jpg',\n",
       " 'http://www.aceshowbiz.com/images/news/thomas-roberts-ties-the-knot-with-patrick-abner.jpg',\n",
       " 'http://upload.wikimedia.org/wikipedia/commons/6/6e/Gareth_Thomas_(rugby_player).jpg',\n",
       " 'http://en.wikipedia.org/wiki/File:Gareth_Thomas_(rugby_player).jpg',\n",
       " 'http://www.worldoftomoffinland.com/tomsblog/wp-content/uploads/2012/09/Life-and-work-of-a-gay-hero-cover.jpg',\n",
       " 'http://www.doubletakedebate.com/wp-content/uploads/2015/09/Thomas-H.jpg',\n",
       " 'http://movietvtechgeeks.com/wp-content/uploads/2014/08/gareth-thomas-shirtless-bulge-gay-rugby-players-movie-2014.jpg',\n",
       " 'http://www.malecelebnews.com/wp-content/images/2013/01/Rob-James-Collier-Talks-About-His-Gay-Character-in-OUT-01.jpg',\n",
       " 'http://static.guim.co.uk/sys-images/Observer/Pix/pictures/2010/10/6/1286363581120/Gareth-Thomas-006.jpg',\n",
       " 'http://www.duanemoody.com/images/outtomford.jpg',\n",
       " 'http://queerty-prodweb.s3.amazonaws.com/wp/docs/2013/12/tom-daley-leg-up-gay-fans.jpg',\n",
       " 'http://photos1.blogger.com/blogger/6296/2252/1600/JTT.jpg',\n",
       " 'http://i1.cdnds.net/12/02/618x800/gs_attitude_feb_tom_ellis_3.jpg',\n",
       " 'http://feltbeats.com/wp-content/uploads/2011/03/Tom_Felton_Gay_Magazin_Seite_2.jpg',\n",
       " 'http://cdn.crushable.com/files/2011/10/600full-thomas-jane.jpg',\n",
       " 'https://static-secure.guim.co.uk/sys-images/Football/Pix/pictures/2014/1/8/1389179385721/Thomas-Hitzlsperger-011.jpg',\n",
       " 'http://i1.ytimg.com/vi/ZEOmTyoBZv0/maxresdefault.jpg',\n",
       " 'http://assets.sbnation.com/assets/3184961/daley2.jpg',\n",
       " 'http://i.huffpost.com/gen/1550506/thumbs/o-THOMAS-HITZLSPERGER-COMES-OUT-facebook.jpg',\n",
       " 'http://malecelebnews.com/wp-content/images/2012/08/Tom-Daley-gets-gay-hate-tweets-06.jpg',\n",
       " 'http://static.tvtropes.org/pmwiki/pub/images/tom_of_finland_guy_2391.png',\n",
       " 'http://queerty-prodweb.s3.amazonaws.com/wp/docs/2013/02/downton-abbey-thomas-gay-kiss.jpg']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from html.parser import HTMLParser  \n",
    "from urllib.request import urlopen  \n",
    "from urllib import parse\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from string import digits\n",
    "import csv\n",
    "import json\n",
    "\n",
    "class LinkParser(HTMLParser):\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "           if tag == 'a':\n",
    "            for (key, value) in attrs:\n",
    "                if key == 'href':\n",
    "                    \n",
    "                    newUrl = parse.urljoin(self.baseUrl, value)\n",
    " \n",
    "                    self.links = self.links + [newUrl]\n",
    "\n",
    "    def getLinks(self, url):\n",
    "        self.links = []\n",
    "  \n",
    "        self.baseUrl = url\n",
    "\n",
    "        response = urlopen(url)\n",
    "\n",
    "     \n",
    "        htmlBytes = response.read()\n",
    "\n",
    "        htmlString = htmlBytes.decode(\"utf-8\")\n",
    "        self.feed(htmlString)\n",
    "        return htmlString, self.links[4:16]\n",
    "       \n",
    "            \n",
    "def randname():\n",
    "   \n",
    "    ''' returns a single random name from the us census'''\n",
    "   \n",
    "    fhand = urlopen('http://deron.meranda.us/data/census-derived-all-first.txt')\n",
    "    table =  [line.strip() for line in fhand]\n",
    "    tsplit = [t.split() for t in table]\n",
    "    namebyte = [tsplit[i][0] for i in range(len(tsplit))]\n",
    "    names = [i.decode('UTF-8') for i in namebyte]\n",
    "\n",
    "    return random.choice(names)\n",
    "\n",
    "def randword():\n",
    "    \n",
    "    ''' returns a random word from a list of 1524 of the most common nouns in the english language '''\n",
    "    \n",
    "    fhand = urlopen('http://www.talkenglish.com/vocabulary/top-1500-nouns.aspx').read()\n",
    "    stringform = fhand.decode(\"utf-8\")\n",
    "    soup = bs(stringform, 'html.parser')\n",
    "    tables = soup.find_all('tr')\n",
    "    wordtags = tables[4:-1]\n",
    "    words = [word.get_text() for word in wordtags]\n",
    "    words = [w.strip() for w in words]\n",
    "    words = [re.sub('\\(.+\\)', '', wo) for wo in words]\n",
    "    # removes part of string in parentheses\n",
    "    \n",
    "    words = [w.translate({ord(k): None for k in digits}) for w in words]\n",
    "    # removes numbers from each string\n",
    "    words = [w.strip() for w in words]\n",
    "    # removes whitespace around string\n",
    "    return random.choice(words)\n",
    "    \n",
    "    \n",
    "\n",
    "def searchaddress():\n",
    "    \n",
    "    ''' takes a random word and formats into URL, returns url1 for first search page \n",
    "        and url2 for second search page '''                     \n",
    "    \n",
    "    base = 'http://www.whosdatedwho.com/search?q='\n",
    "    base2 = '&page=2'\n",
    "    word = randword()\n",
    "    url = base + word\n",
    "    url2 = base + word + base2\n",
    "\n",
    "    return url, url2, word\n",
    "\n",
    "def picfinder(url):\n",
    "    try:\n",
    "        rawdata = urlopen(url).read()\n",
    "        rawdata = rawdata.decode(\"utf-8\")\n",
    "\n",
    "        soup = bs(rawdata, 'html.parser')\n",
    "\n",
    "        imgs = soup.find_all('img')\n",
    "        srcs = ([img['src'] for img in imgs])\n",
    "        picture = (srcs[1])\n",
    "\n",
    "        if picture == 'http://img3.bdbphotos.com/images/130x130/5/g/5gmnjvqhgqy8jyh.jpg?skj2io4l':\n",
    "            return 'http://vignette3.wikia.nocookie.net/spore/images/6/6c/Question-mark.png/revision/latest?cb=20110427230528'\n",
    "        # profiles with no picture return selena gomez (current top celebrity)\n",
    "        # so an image of a question mark is returned if selena gomez if found\n",
    "        # could be updated to automatically find the top celebrity\n",
    "        else:\n",
    "            return picture\n",
    "    except:\n",
    "        return 'no pic'\n",
    "    \n",
    "    \n",
    "\n",
    "def celebinfo(url):\n",
    "    \n",
    "    ''' returns a dictionary  containing information about the celebrity '''\n",
    "    \n",
    "    rawdata = urlopen(url).read()\n",
    "    rawdata = rawdata.decode(\"utf-8\")\n",
    "    soup = bs(rawdata, 'html.parser')\n",
    "    try:\n",
    "        tables = soup.find_all('table')\n",
    "        data = tables[1].find_all('td')\n",
    "\n",
    "        keys = data[::2]\n",
    "        keys = [k.get_text() for k in keys]\n",
    "        keys = [k.strip() for k in keys]\n",
    "\n",
    "        vals = data[1::2]\n",
    "        vals = [v.get_text() for v in vals]\n",
    "        vals = [v.strip() for v in vals]\n",
    "\n",
    "        dictm = {k: v for k, v in zip(keys, vals)}\n",
    "        \n",
    "        imlink = picfinder(url)\n",
    "        \n",
    "        dictm['Image Source'] = imlink\n",
    "        \n",
    "        return dictm\n",
    "    \n",
    "    except:\n",
    "        return 'empty'\n",
    "\n",
    "\n",
    "def childage(url):\n",
    "     \n",
    "    ''' returns a list of the ages of each of the children '''\n",
    "    \n",
    "    rawdata = urlopen(url).read()\n",
    "    rawdata = rawdata.decode(\"utf-8\")\n",
    "\n",
    "    soup = bs(rawdata, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    data = tables[3].find_all('td')\n",
    "    \n",
    "    data = [d.get_text() for d in data]\n",
    "    data = [d.strip() for d in data]\n",
    "    \n",
    "    agestr = [x for x in data if \"years\" in x ]\n",
    "    \n",
    "    ages = []\n",
    "    \n",
    "    for i in range(len(agestr)):\n",
    "        ages.append([int(s) for s in agestr[i].split() if s.isdigit()])\n",
    "        \n",
    "    ages = [ages[i][0] for i in range(len(ages))]\n",
    "    \n",
    "    return ages\n",
    "\n",
    "\n",
    "def string_found(string1, string2):\n",
    "    if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bing_pic_finder(word):\n",
    "    \n",
    "    word = word.replace(' ','%20')\n",
    "    rawdata = urlopen('http://www.bing.com/images/search?q=' + word + '&go=Search&qs=n&form=QBILPG&pq=' + word + '&sc=0-0&sp=-1&sk=').read()\n",
    "    rawdata = rawdata.decode(\"utf-8\")\n",
    "\n",
    "    soup = bs(rawdata, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    hrefs = [link['href'] for link in links]\n",
    "    pics = [href for href in hrefs if href.endswith(('.png', '.PNG', '.jpg', '.JPG'))] \n",
    "\n",
    "    return pics\n",
    "\n",
    "\n",
    "def spider(): \n",
    "    print('Starting Spider')\n",
    "    maxPages = 120\n",
    "    numberVisited = 0\n",
    "    interesting = False\n",
    "    \n",
    "    while numberVisited < maxPages and not interesting: \n",
    "\n",
    "        numberVisited = numberVisited + 1\n",
    "        \n",
    "        url1, url2, searchedword = searchaddress()\n",
    "        \n",
    "        urls = [url1, url2]\n",
    "        \n",
    "        for url in urls:\n",
    "        \n",
    "        \n",
    "            parser = LinkParser()\n",
    "            data, links = parser.getLinks(url)\n",
    "\n",
    "\n",
    "            infos = [celebinfo(link) for link in links]\n",
    "     \n",
    "            for info in random.sample(infos, len(infos)):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    firstname = info.get('First Name')\n",
    "                    firstname = firstname + ' x'\n",
    "    \n",
    "\n",
    "                    if string_found(searchedworld.title(), firstname) == True or string_found('The', firstname) == True:\n",
    "                        \n",
    "                        interesting = True\n",
    "                   \n",
    "                        return info\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "                try:\n",
    "\n",
    "                    lastname = info.get('Last Name')\n",
    "                    lastname = lastname + ' x'\n",
    "\n",
    "\n",
    "                    if string_found(searchedword.title(), lastname) == True or string_found('The', lastname) == True:\n",
    "                        \n",
    "                        interesting = True\n",
    "                        return info\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "\n",
    "                    midname = info.get('Middle Name')\n",
    "                    midname = midname + ' x'\n",
    "\n",
    "\n",
    "                    if string_found(searchedword.title(), midname) == True or string_found('The', midname) == True:\n",
    "                        \n",
    "                        interesting = True\n",
    "                        return info\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "bing_pic_finder('thomas is gay')\n",
    "# with open(r'gerardisgay.csv', 'a') as f:\n",
    "#     for i in range(2000):\n",
    "#         try:\n",
    "#             x = spider()\n",
    "#             f.write(\"%s\\n\" % x)\n",
    "            \n",
    "#         except:\n",
    "#             print('poo')\n",
    "\n",
    "# with open('gerard_is_very_gay.json', 'w') as outfile:\n",
    "#     for i in range(2):\n",
    "#         try:\n",
    "#             data = spider()\n",
    "#             json.dump(data, outfile, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "#         except:\n",
    "#             print('poo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
